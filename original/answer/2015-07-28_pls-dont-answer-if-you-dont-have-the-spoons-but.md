---
id: 125285395589
slug: pls-dont-answer-if-you-dont-have-the-spoons-but
type: answer
date: 2015-07-28 21:06:35 GMT
tags:
- barbaricyip
- discussing discourse
---
question: pls don't answer if you don't have the spoons, but is the problem with a veracity rating that no judgment of veracity can be without context/political agenda? or that ppl still don't trust social media reports of events to be "verifiable"? idk i feel like i get it but i'd like to know if there's something else suspect that i'm missing.

answer: <p>yes&hellip; to an extent you have it right.</p><p>i didn’t have the concentration and energy to actually read through the paper (and def. not the math skills) but i looked at some of it and&hellip; </p><p>like their example case, which i understand, is ‘obama born usa’ and ‘obama born kenya’ and there is a discussion about how guess the probability of which of these is actually true&hellip;</p><p>but that’s one part of the problem: the algorithm won’t determine what is actually fact or fiction, but make a probable guess. </p><p>but the real problem is perhaps a little deeper and more philosophical. humans have been asking what counts as ‘true’ and what counts as ‘knowledge’ for pretty much ever. and this comes to bear on this notion of ‘knowledge based trust’ (as the paper calls it). </p><p>the theory of truth that you work with impacts the epistemology (theory of knowledge and what counts as knowledge) you work with. </p><p>like. these are actually complex problems that have yet to reach any level of consensus.</p><p>even if we step back from the philosophical/abstract problems, we can look at more concrete examples of how thorny this can be in real life. </p><p>best example? school text books. anyone whose spent a great deal of time critically engaging the ‘knowledge’ we were taught in school knows that we were taught outright lies, distortions, fictions, half-truths, and omissions. however, school textbooks are often considered the apex of ‘trustworthiness’ and we are taught to trust in their authority by pretty much everyone at every step.</p><p>or another problem with the whole business is that this computational model will have zero ability to distinguish garbage theories based on facts from sound theories based on facts. as a person who consistently and frequently has science ‘facts’ used against them (ie: ppl with XY chromosomes are male!) and who deals with political and social groups who derive garbage theories from those facts (ie: trans women with XY chromosomes are male!), i know that this model will rank a page like this as equal footing with the opposing theory (or possibly _even lower_).</p><p>the crux of the issue here is that logical entailment (the property between an argument and its conclusion/s) cannot be determined by an algorithm, in part because this is a _meta logical_ concept that cannot be determined within the system. heck. i don’t even need to get into entailment and soundness of arguments:</p><p>1. ppl with XY chromosomes are male</p><p>2. trans women have XY chromosomes</p><p>therefore: trans women are male</p><p>this is a perfectly sound and valid argument. all of the premises are true. the conclusion is true and derived from the premises. so a page containing these ‘facts’ will achieve a higher search ranking that one that argues that ‘trans women are female’ despite the above ‘facts’. </p><p>then we can also get into a discussion about truth and objectivity&hellip; which is more of a post-modern discussion about the issue raised here. </p><p>one example: suppose there is a blog by someone who is colour-blind and is about their experience being colour-blind (we’re assuming total monochormacy). and so their blog frequently contains phrases like “grass is grey” or “the sky is grey”. based on this search criteria such a page would get lower page ranks because of the inclusion of all these ‘false facts’. Except that these statements aren’t false. not to the person writing them. and sure&hellip; one might argue that ‘grass is objectively green’ but that isn’t really the point, is it? </p><p>all of this to say: truth and knowledge is really really fucking complicated. and i don’t want google trying to decide what is and isn’t true on my behalf. not when their sole purpose is to sell advertising. </p>